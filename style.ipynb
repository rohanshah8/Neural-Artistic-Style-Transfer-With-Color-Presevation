{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5820da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rohanshah/Neural Artistic style/Neural_Artistic_Style\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/rohanshah/aip_project/Neural_Artistic_Style/')\n",
    "import vgg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "content_layer = 'relu4_2'\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']\n",
    "\n",
    "# Convert the art style of \"content\" to the art style of \"style\"\n",
    "# Returns np array containnig the result image\n",
    "def convert_style(net_path, content, styles, iterations, content_weight, style_weight, style_merge_weight, learning_rate, check_per_iteration, preserve_color):\n",
    "    print(\"Total iterations: {0}\".format(iterations))\n",
    "\n",
    "    # If preserve color, then transfer color scheme for style image first\n",
    "    if preserve_color:\n",
    "        print(\"Options detected: preserve original content color scheme\")\n",
    "        for style in styles:\n",
    "            style = transfer_color(content, style)\n",
    "\n",
    "    # Construct merge weight for styles\n",
    "    if style_merge_weight == None:\n",
    "        style_merge_weight = [1.0 / len(styles) for _ in styles]\n",
    "\n",
    "    # Store shapes of both images\n",
    "    content_shape = (1,) + content.shape\n",
    "    style_shapes = [(1,) + style.shape for style in styles]\n",
    "\n",
    "    # Features\n",
    "    content_features = {}\n",
    "    style_features = [{} for _ in styles]\n",
    "\n",
    "    # Extract features for content\n",
    "    g = tf.Graph()\n",
    "    with g.as_default(), tf.Session() as session:\n",
    "        # Build convnet in tensorflow\n",
    "        image = tf.placeholder('float', shape = content_shape)\n",
    "        net, mean = vgg.build_net(net_path, image)\n",
    "        # Extract features\n",
    "        preprocessed_content = np.array([vgg.pre_process_image(content, mean)])\n",
    "        content_features[content_layer] = net[content_layer].eval(\n",
    "            feed_dict = {image: preprocessed_content})\n",
    "\n",
    "    print(\"Content feature extracted\")\n",
    "\n",
    "    for i, style in enumerate(styles):\n",
    "        # Extract features for style\n",
    "        g = tf.Graph()\n",
    "        with g.as_default(), tf.Session() as session:\n",
    "            # Build convnet\n",
    "            image = tf.placeholder('float', shape = style_shapes[i])\n",
    "            net, _ = vgg.build_net(net_path, image)\n",
    "            # Extract style features\n",
    "            preprocessed_style = np.array([vgg.pre_process_image(style, mean)])\n",
    "            for layer in style_layers:\n",
    "                layer_features = net[layer].eval(\n",
    "                    feed_dict = {image: preprocessed_style})\n",
    "                style_features[i][layer] = layer_features\n",
    "\n",
    "    print(\"Style feature extracted\")\n",
    "\n",
    "    # Reconstruct image through backprogpagation\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # Random generated image as initial state\n",
    "        image = tf.Variable(tf.random_normal(content_shape) * 0.256)\n",
    "        # Build convnet for backprogpagation\n",
    "        net, _ = vgg.build_net(net_path, image)\n",
    "\n",
    "        # Calculate content loss\n",
    "        content_loss =  2 * tf.nn.l2_loss(net[content_layer] - content_features[content_layer]) / content_features[content_layer].size\n",
    "\n",
    "        # Calculate style loss\n",
    "        style_loss = 0\n",
    "\n",
    "        for i, _ in enumerate(style_features):\n",
    "            curr_style_loss = 0\n",
    "            for layer in style_layers:\n",
    "                # Gram of original convnet layers\n",
    "                net_layer = net[layer]\n",
    "                _, height, width, channels = map(lambda i: i, net_layer.get_shape())\n",
    "                net_size = height * width * channels\n",
    "                net_features = tf.reshape(net_layer, (-1, channels))\n",
    "                net_gram = tf.matmul(tf.transpose(net_features), net_features) / net_size\n",
    "                # Gram of style\n",
    "                style_layer = style_features[i][layer]\n",
    "                style_layer_features = np.reshape(style_layer, (-1, style_layer.shape[3]))\n",
    "                style_gram = np.matmul(style_layer_features.T, style_layer_features) / style_layer_features.size\n",
    "                # Style loss of current layer\n",
    "                curr_style_loss += 2 * tf.nn.l2_loss(net_gram - style_gram) / style_gram.size\n",
    "            style_loss += style_merge_weight[i] * curr_style_loss\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = content_weight * content_loss + style_weight * style_loss\n",
    "\n",
    "        # Train step\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "        # Optimize\n",
    "        least_loss = float('inf')\n",
    "        best_img = None\n",
    "        with tf.Session() as session:\n",
    "            session.run(tf.initialize_all_variables())\n",
    "\n",
    "            for i in range(iterations):\n",
    "                train_step.run()\n",
    "                print(\"Iteration {0}/{1} complete.\".format(i + 1, iterations))\n",
    "\n",
    "                # If a check or last iteration is reached\n",
    "                # Check if current image produces the least loss\n",
    "                if i % check_per_iteration == 0 or i == iterations - 1:\n",
    "                    curr_loss = total_loss.eval()\n",
    "                    if (curr_loss < least_loss):\n",
    "                        least_loss = curr_loss\n",
    "                        best_img = image.eval()\n",
    "\n",
    "        return vgg.restore_image(best_img.reshape(content_shape[1:]), mean)\n",
    "\n",
    "# Transfer the color histogram of \"content\" to \"style\"\n",
    "# Returns np array containing result style image\n",
    "def transfer_color(content, style):\n",
    "    import scipy.linalg as sl\n",
    "    # Mean and covariance of content\n",
    "    content_mean = np.mean(content, axis = (0, 1))\n",
    "    content_diff = content - content_mean\n",
    "    content_diff = np.reshape(content_diff, (-1, content_diff.shape[2]))\n",
    "    content_covariance = np.matmul(content_diff.T, content_diff) / (content_diff.shape[0])\n",
    "\n",
    "    # Mean and covariance of style\n",
    "    style_mean = np.mean(style, axis = (0, 1))\n",
    "    style_diff = style - style_mean\n",
    "    style_diff = np.reshape(style_diff, (-1, style_diff.shape[2]))\n",
    "    style_covariance = np.matmul(style_diff.T, style_diff) / (style_diff.shape[0])\n",
    "\n",
    "    # Calculate A and b\n",
    "    A = np.matmul(sl.sqrtm(content_covariance), sl.inv(sl.sqrtm(style_covariance)))\n",
    "    b = content_mean - np.matmul(A, style_mean)\n",
    "\n",
    "    # Construct new style\n",
    "    new_style = np.reshape(style, (-1, style.shape[2])).T\n",
    "    new_style = np.matmul(A, new_style).T\n",
    "    new_style = np.reshape(new_style, style.shape)\n",
    "    new_style = new_style + b\n",
    "\n",
    "    return new_style\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
